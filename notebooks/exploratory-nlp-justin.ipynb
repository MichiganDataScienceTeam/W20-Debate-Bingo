{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbasecondad0aa168c2d0047268f657f9208d7a7c9",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debate Exploration Using Natural Language Processing\n",
    "## Bag of Words Model\n",
    "### Warning: this notebook takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import string\n",
    "import random\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(str):\n",
    "    for char in str:\n",
    "        if char in string.punctuation:\n",
    "            str = str.replace(char, '')\n",
    "    return str\n",
    "\n",
    "def add_to_dict(str, dict):\n",
    "    for word in str.split():\n",
    "        if not word.lower() in dict:\n",
    "            dict[word.lower()] = len(dict)\n",
    "    return dict\n",
    "\n",
    "def extract_dictionary(df):\n",
    "    \"\"\"\n",
    "    Reads a panda dataframe, and returns a dictionary of distinct words\n",
    "    mapping from each distinct word to its index (ordered by when it was found).\n",
    "    Input:\n",
    "        df: dataframe/output of load_data()\n",
    "    Returns:\n",
    "        a dictionary of distinct words that maps each distinct word\n",
    "        to a unique index corresponding to when it was first found while\n",
    "        iterating over all words in each speech in the dataframe df\n",
    "    \"\"\"\n",
    "    df.text = df.text.apply(remove_punctuation)\n",
    "    word_dict = {}\n",
    "    df.apply(lambda x: add_to_dict(x.text, word_dict), axis = 1)\n",
    "    print(\"Number of unique words: \" + str(len(word_dict)))\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns_to_feature_matrix(features, matrix):\n",
    "    matrix = np.append(matrix, np.column_stack(features).T, axis = 1)\n",
    "    return matrix\n",
    "\n",
    "def generate_feature_matrix(df, word_dict, scale = 'None'):\n",
    "    \"\"\"\n",
    "    Reads a dataframe and the dictionary of unique words\n",
    "    to generate a matrix of {1, 0} feature vectors for each speech.\n",
    "    Use the word_dict to find the correct index to set to 1 for each place\n",
    "    in the feature vector. The resulting feature matrix should be of\n",
    "    dimension (number of speeches, number of words).\n",
    "    Input:\n",
    "        df: dataframe that has the ratings and labels\n",
    "        word_list: dictionary of words mapping to indices\n",
    "    Returns:\n",
    "        a feature matrix of dimension (number of reviews, number of words)\n",
    "    \"\"\"\n",
    "    number_of_speeches = df.shape[0]\n",
    "    number_of_words = len(word_dict)\n",
    "    feature_matrix = np.zeros((number_of_speeches, number_of_words))\n",
    "    for i in range(0, number_of_speeches):\n",
    "        for word in word_dict:\n",
    "            if word in str(df.text.iloc[i]).lower().split():\n",
    "                feature_matrix[i, word_dict[word]] = 1\n",
    "\n",
    "    print(\"Average number of non-zero features: \" + str(np.mean(np.sum(feature_matrix, axis = 1))))\n",
    "    if(scale == \"None\"):\n",
    "        return feature_matrix\n",
    "    elif(scale == \"Normalize\"):\n",
    "        return feature_matrix/np.linalg.norm(feature_matrix, axis = 1)[:,None]\n",
    "    elif(scale == \"Scale\"):\n",
    "        return feature_matrix*np.linalg.norm(feature_matrix, axis = 1)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(candidate, dataframe, dictionary):\n",
    "    positiveDF = dataframe[dataframe.name == candidate].copy()\n",
    "    negativeDF = dataframe[dataframe.name != candidate].copy()\n",
    "    positive_train = positiveDF.sample(frac = 0.75)\n",
    "    positive_test = pd.concat([positiveDF, positive_train]).drop_duplicates(keep=False)\n",
    "    negative_train = negativeDF.sample(frac = (len(positiveDF)/len(negativeDF))*0.75)\n",
    "    negative_test = pd.concat([negativeDF, negative_train]).drop_duplicates(keep=False).sample(frac = (len(positiveDF)/len(negativeDF))*0.25)\n",
    "    X_train = pd.concat([positive_train, negative_train]).reset_index(drop=True).copy()\n",
    "    X_test = pd.concat([positive_test,\n",
    "                        negative_test]).reset_index(drop=True).copy()\n",
    "    Y_train = X_train.name == candidate\n",
    "    Y_test = X_test.name == candidate\n",
    "    print(\"Getting training feature matrix... \")\n",
    "    X_train = generate_feature_matrix(X_train, dictionary)\n",
    "    print(\"Getting testing feature matrix... \")\n",
    "    X_test = generate_feature_matrix(X_test, dictionary)\n",
    "    return (X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(y_true, y_pred, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Calculates the performance metric as evaluated on the true labels\n",
    "    y_true versus the predicted labels y_pred.\n",
    "    Input:\n",
    "        y_true: (n,) array containing known labels\n",
    "        y_pred: (n,) array containing predicted scores\n",
    "        metric: string specifying the performance metric (default='accuracy'\n",
    "                 other options: 'f1-score', 'auroc', 'precision', 'sensitivity',\n",
    "                 and 'specificity')\n",
    "    Returns:\n",
    "        the performance as an np.float64\n",
    "    \"\"\"\n",
    "    tp = np.logical_and(y_true == 1, y_pred == 1).sum()\n",
    "    tn = np.logical_and(y_true == 0, y_pred == 0).sum()\n",
    "    fp = np.logical_and(y_true != 1, y_pred == 1).sum()\n",
    "    fn = np.logical_and(y_true != 0, y_pred == 0).sum() \n",
    "    return np.float64((tp + tn)/(tp + tn + fp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(clf, X, y, k=5, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Splits the data X and the labels y into k-folds and runs k-fold\n",
    "    cross-validation: for each fold i in 1...k, trains a classifier on\n",
    "    all the data except the ith fold, and tests on the ith fold.\n",
    "    Calculates the k-fold cross-validation performance metric for classifier\n",
    "    clf by averaging the performance across folds.\n",
    "    Input:\n",
    "        clf: an instance of SVC()\n",
    "        X: (n,d) array of feature vectors, where n is the number of examples\n",
    "           and d is the number of features\n",
    "        y: (n,) array of binary labels {1,-1}\n",
    "        k: an int specifying the number of folds (default=5)\n",
    "        metric: string specifying the performance metric (default='accuracy'\n",
    "             other options: 'f1-score', 'auroc', 'precision', 'sensitivity',\n",
    "             and 'specificity')\n",
    "    Returns:\n",
    "        average 'test' performance across the k folds as np.float64\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    skf = StratifiedKFold(n_splits = k, shuffle = False)\n",
    "    skf.get_n_splits(X, y)\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "        scores.append(performance(y_test, pred, metric))\n",
    "    return np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_classifier(penalty='l2', c=1.0, degree=1, r=0.0, class_weight='balanced', multi_class = 'ovr'):\n",
    "    \"\"\"\n",
    "    Return a linear svm classifier based on the given\n",
    "    penalty function and regularization parameter c.\n",
    "    \"\"\"\n",
    "    if penalty == 'l2':\n",
    "        return SVC(C = c, kernel = 'linear', coef0 = r, degree = degree, class_weight = class_weight)\n",
    "    else:\n",
    "        return LinearSVC(penalty = penalty, C = c, dual = False, max_iter = 100000, multi_class = 'ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_param_linear(X, y, k=5, metric=\"accuracy\", C_range = [], penalty='l2', class_weight = 'balanced'):\n",
    "    \"\"\"\n",
    "    Sweeps different settings for the hyperparameter of a linear-kernel SVM,\n",
    "    calculating the k-fold CV performance for each setting on X, y.\n",
    "    Input:\n",
    "        X: (n,d) array of feature vectors, where n is the number of examples\n",
    "        and d is the number of features\n",
    "        y: (n,) array of binary labels {1,-1}\n",
    "        k: int specifying the number of folds (default=5)\n",
    "        metric: string specifying the performance metric (default='accuracy',\n",
    "             other options: 'f1-score', 'auroc', 'precision', 'sensitivity',\n",
    "             and 'specificity')\n",
    "        C_range: an array with C values to be searched over\n",
    "    Returns:\n",
    "        The parameter value for a linear-kernel SVM that maximizes the\n",
    "        average 5-fold CV performance.\n",
    "    \"\"\"\n",
    "    best_score = 0\n",
    "    best_c = C_range[0]\n",
    "    print(\"Getting best C parameter... \")\n",
    "    for C in C_range:\n",
    "        clf = select_classifier(penalty = penalty, c = C, class_weight = class_weight)\n",
    "        score = cv(clf, X, y, k, metric)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_c = C\n",
    "    \n",
    "    return (best_c, best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data Frame and Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Getting dictionary... \nNumber of unique words: 8937\n"
    }
   ],
   "source": [
    "fname = \"../data/transcripts_cleaned.csv\"\n",
    "debates = pd.read_csv(fname)\n",
    "debates = debates[debates.name != 'Non-candidate']\n",
    "print(\"Getting dictionary... \")\n",
    "dictionary = extract_dictionary(debates)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting Parameters\n",
    "### Train a model on each candidate's speech and return the penalty coefficient that leads to the best predictions\n",
    "You don't need to run this if you'd rather just use my chosen parameter of $C = 0.1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nfor candidate in candidates:\\n    print(candidate + \": \")\\n    X_train, Y_train, X_test, Y_test, dictionary = get_data(candidate)\\n    C_range = [10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3]\\n    print(select_param_linear(X_train, Y_train, k = 5, C_range = C_range, penalty = \\'l2\\'))\\n'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = ['Biden', 'Buttigieg', 'Klobuchar', 'Sanders', 'Warren']\n",
    "\"\"\"\n",
    "for candidate in candidates:\n",
    "    print(candidate + \": \")\n",
    "    X_train, Y_train, X_test, Y_test, dictionary = get_data(candidate)\n",
    "    C_range = [10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3]\n",
    "    print(select_param_linear(X_train, Y_train, k = 5, C_range = C_range, penalty = 'l2'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Models\n",
    "### Using the majority-vote best C-parameter, train models on each candidate and get words with high coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "raining feature matrix... \nAverage number of non-zero features: 51.06310679611651\nGetting testing feature matrix... \nAverage number of non-zero features: 45.5\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 50.200542005420054\nGetting testing feature matrix... \nAverage number of non-zero features: 49.739495798319325\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 46.3\nGetting testing feature matrix... \nAverage number of non-zero features: 39.76923076923077\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 47.19665271966527\nGetting testing feature matrix... \nAverage number of non-zero features: 41.58552631578947\nFold 10: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 45.88740458015267\nGetting testing feature matrix... \nAverage number of non-zero features: 46.61212121212121\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 49.34466019417476\nGetting testing feature matrix... \nAverage number of non-zero features: 51.053030303030305\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 48.77506775067751\nGetting testing feature matrix... \nAverage number of non-zero features: 57.52100840336134\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 46.504444444444445\nGetting testing feature matrix... \nAverage number of non-zero features: 42.28671328671329\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 45.18410041841004\nGetting testing feature matrix... \nAverage number of non-zero features: 49.9671052631579\nFold 11: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 46.93129770992366\nGetting testing feature matrix... \nAverage number of non-zero features: 46.02424242424242\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 49.91747572815534\nGetting testing feature matrix... \nAverage number of non-zero features: 53.10606060606061\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 48.00542005420054\nGetting testing feature matrix... \nAverage number of non-zero features: 54.78151260504202\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 43.75555555555555\nGetting testing feature matrix... \nAverage number of non-zero features: 46.74825174825175\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 46.65271966527197\nGetting testing feature matrix... \nAverage number of non-zero features: 47.901315789473685\nFold 12: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 46.11068702290076\nGetting testing feature matrix... \nAverage number of non-zero features: 51.00606060606061\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 49.87378640776699\nGetting testing feature matrix... \nAverage number of non-zero features: 47.916666666666664\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 50.34417344173442\nGetting testing feature matrix... \nAverage number of non-zero features: 52.924369747899156\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 46.34\nGetting testing feature matrix... \nAverage number of non-zero features: 50.37062937062937\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 44.03347280334728\nGetting testing feature matrix... \nAverage number of non-zero features: 52.44078947368421\nFold 13: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 45.61832061068702\nGetting testing feature matrix... \nAverage number of non-zero features: 49.96363636363636\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 50.54611650485437\nGetting testing feature matrix... \nAverage number of non-zero features: 46.303030303030305\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 51.794037940379404\nGetting testing feature matrix... \nAverage number of non-zero features: 49.621848739495796\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 44.46222222222222\nGetting testing feature matrix... \nAverage number of non-zero features: 42.25874125874126\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 48.22594142259414\nGetting testing feature matrix... \nAverage number of non-zero features: 47.526315789473685\nFold 14: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 46.784351145038165\nGetting testing feature matrix... \nAverage number of non-zero features: 47.43030303030303\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 48.28883495145631\nGetting testing feature matrix... \nAverage number of non-zero features: 56.25757575757576\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 49.85094850948509\nGetting testing feature matrix... \nAverage number of non-zero features: 48.91596638655462\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 45.004444444444445\nGetting testing feature matrix... \nAverage number of non-zero features: 45.57342657342657\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 45.84309623430963\nGetting testing feature matrix... \nAverage number of non-zero features: 43.36184210526316\nFold 15: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 46.66793893129771\nGetting testing feature matrix... \nAverage number of non-zero features: 47.86060606060606\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 50.63106796116505\nGetting testing feature matrix... \nAverage number of non-zero features: 46.946969696969695\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 53.048780487804876\nGetting testing feature matrix... \nAverage number of non-zero features: 48.60504201680672\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 44.77333333333333\nGetting testing feature matrix... \nAverage number of non-zero features: 46.56643356643357\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 47.36192468619247\nGetting testing feature matrix... \nAverage number of non-zero features: 45.44078947368421\nFold 16: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 46.25763358778626\nGetting testing feature matrix... \nAverage number of non-zero features: 48.52121212121212\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 52.38592233009709\nGetting testing feature matrix... \nAverage number of non-zero features: 49.28030303030303\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 50.176151761517616\nGetting testing feature matrix... \nAverage number of non-zero features: 48.94957983193277\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 44.03111111111111\nGetting testing feature matrix... \nAverage number of non-zero features: 46.85314685314685\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 45.94351464435147\nGetting testing feature matrix... \nAverage number of non-zero features: 46.81578947368421\nFold 17: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 46.541984732824424\nGetting testing feature matrix... \nAverage number of non-zero features: 45.333333333333336\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 50.59708737864078\nGetting testing feature matrix... \nAverage number of non-zero features: 47.31818181818182\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 50.609756097560975\nGetting testing feature matrix... \nAverage number of non-zero features: 49.075630252100844\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 45.91777777777778\nGetting testing feature matrix... \nAverage number of non-zero features: 46.88811188811189\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 45.56485355648535\nGetting testing feature matrix... \nAverage number of non-zero features: 45.35526315789474\nFold 18: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 48.88549618320611\nGetting testing feature matrix... \nAverage number of non-zero features: 39.93939393939394\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 52.54368932038835\nGetting testing feature matrix... \nAverage number of non-zero features: 47.696969696969695\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 51.65040650406504\nGetting testing feature matrix... \nAverage number of non-zero features: 39.596638655462186\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 44.044444444444444\nGetting testing feature matrix... \nAverage number of non-zero features: 48.3006993006993\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 46.27824267782427\nGetting testing feature matrix... \nAverage number of non-zero features: 44.151315789473685\nFold 19: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 49.44847328244275\nGetting testing feature matrix... \nAverage number of non-zero features: 46.593939393939394\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 51.810679611650485\nGetting testing feature matrix... \nAverage number of non-zero features: 48.46969696969697\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 50.77506775067751\nGetting testing feature matrix... \nAverage number of non-zero features: 46.94957983193277\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 45.12444444444444\nGetting testing feature matrix... \nAverage number of non-zero features: 41.43356643356643\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 45.30125523012552\nGetting testing feature matrix... \nAverage number of non-zero features: 47.6578947368421\nFold 20: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 48.4942748091603\nGetting testing feature matrix... \nAverage number of non-zero features: 47.29090909090909\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 51.86893203883495\nGetting testing feature matrix... \nAverage number of non-zero features: 50.64393939393939\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 50.010840108401084\nGetting testing feature matrix... \nAverage number of non-zero features: 48.016806722689076\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 43.92\nGetting testing feature matrix... \nAverage number of non-zero features: 47.68531468531469\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 46.37656903765691\nGetting testing feature matrix... \nAverage number of non-zero features: 44.453947368421055\nFold 21: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 46.45992366412214\nGetting testing feature matrix... \nAverage number of non-zero features: 46.733333333333334\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 51.52427184466019\nGetting testing feature matrix... \nAverage number of non-zero features: 51.65151515151515\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 50.05420054200542\nGetting testing feature matrix... \nAverage number of non-zero features: 51.075630252100844\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 45.913333333333334\nGetting testing feature matrix... \nAverage number of non-zero features: 48.50349650349651\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 46.52301255230125\nGetting testing feature matrix... \nAverage number of non-zero features: 45.05921052631579\nFold 22: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 47.36068702290076\nGetting testing feature matrix... \nAverage number of non-zero features: 46.96969696969697\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 49.86893203883495\nGetting testing feature matrix... \nAverage number of non-zero features: 50.871212121212125\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 48.49864498644986\nGetting testing feature matrix... \nAverage number of non-zero features: 54.20168067226891\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 44.16\nGetting testing feature matrix... \nAverage number of non-zero features: 44.34265734265734\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 46.47698744769875\nGetting testing feature matrix... \nAverage number of non-zero features: 46.4078947368421\nFold 23: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 45.60496183206107\nGetting testing feature matrix... \nAverage number of non-zero features: 48.339393939393936\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 50.9247572815534\nGetting testing feature matrix... \nAverage number of non-zero features: 48.416666666666664\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 50.27913279132791\nGetting testing feature matrix... \nAverage number of non-zero features: 50.0\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 46.78666666666667\nGetting testing feature matrix... \nAverage number of non-zero features: 47.35664335664335\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 44.67991631799163\nGetting testing feature matrix... \nAverage number of non-zero features: 44.39473684210526\nFold 24: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 47.9293893129771\nGetting testing feature matrix... \nAverage number of non-zero features: 47.442424242424245\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 48.5752427184466\nGetting testing feature matrix... \nAverage number of non-zero features: 53.68181818181818\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 50.327913279132794\nGetting testing feature matrix... \nAverage number of non-zero features: 52.0672268907563\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 46.75333333333333\nGetting testing feature matrix... \nAverage number of non-zero features: 40.53146853146853\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 45.78451882845188\nGetting testing feature matrix... \nAverage number of non-zero features: 49.0921052631579\nFold 25: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 46.963740458015266\nGetting testing feature matrix... \nAverage number of non-zero features: 48.527272727272724\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 51.53883495145631\nGetting testing feature matrix... \nAverage number of non-zero features: 47.78787878787879\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 48.48509485094851\nGetting testing feature matrix... \nAverage number of non-zero features: 47.67226890756302\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 44.94444444444444\nGetting testing feature matrix... \nAverage number of non-zero features: 46.13286713286713\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 47.03765690376569\nGetting testing feature matrix... \nAverage number of non-zero features: 44.55921052631579\nFold 26: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 46.92748091603053\nGetting testing feature matrix... \nAverage number of non-zero features: 49.624242424242425\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 51.19174757281554\nGetting testing feature matrix... \nAverage number of non-zero features: 48.06818181818182\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 49.737127371273715\nGetting testing feature matrix... \nAverage number of non-zero features: 52.27731092436975\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 44.32\nGetting testing feature matrix... \nAverage number of non-zero features: 50.71328671328671\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 46.31171548117155\nGetting testing feature matrix... \nAverage number of non-zero features: 47.4078947368421\nFold 27: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 45.12786259541985\nGetting testing feature matrix... \nAverage number of non-zero features: 52.4\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 51.77427184466019\nGetting testing feature matrix... \nAverage number of non-zero features: 51.20454545454545\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 51.1219512195122\nGetting testing feature matrix... \nAverage number of non-zero features: 48.0672268907563\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 46.522222222222226\nGetting testing feature matrix... \nAverage number of non-zero features: 46.52447552447553\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 46.64853556485355\nGetting testing feature matrix... \nAverage number of non-zero features: 44.94736842105263\nFold 28: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 47.969465648854964\nGetting testing feature matrix... \nAverage number of non-zero features: 46.73939393939394\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 49.66019417475728\nGetting testing feature matrix... \nAverage number of non-zero features: 51.65151515151515\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 52.22764227642276\nGetting testing feature matrix... \nAverage number of non-zero features: 51.03361344537815\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 46.404444444444444\nGetting testing feature matrix... \nAverage number of non-zero features: 41.70629370629371\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 45.70083682008368\nGetting testing feature matrix... \nAverage number of non-zero features: 48.71052631578947\nFold 29: \nBiden: \nGetting training feature matrix... \nAverage number of non-zero features: 46.75763358778626\nGetting testing feature matrix... \nAverage number of non-zero features: 45.654545454545456\nButtigieg: \nGetting training feature matrix... \nAverage number of non-zero features: 49.39563106796116\nGetting testing feature matrix... \nAverage number of non-zero features: 51.56060606060606\nKlobuchar: \nGetting training feature matrix... \nAverage number of non-zero features: 48.926829268292686\nGetting testing feature matrix... \nAverage number of non-zero features: 54.67226890756302\nSanders: \nGetting training feature matrix... \nAverage number of non-zero features: 47.397777777777776\nGetting testing feature matrix... \nAverage number of non-zero features: 47.71328671328671\nWarren: \nGetting training feature matrix... \nAverage number of non-zero features: 49.17782426778243\nGetting testing feature matrix... \nAverage number of non-zero features: 44.01315789473684\n"
    }
   ],
   "source": [
    "words = {'Biden': [], 'Buttigieg': [], 'Klobuchar': [], 'Sanders': [], 'Warren': []}\n",
    "accuracies = {'Biden': [], 'Buttigieg': [], 'Klobuchar': [], 'Sanders': [], 'Warren': []}\n",
    "coefs = {'Biden': [], 'Buttigieg': [], 'Klobuchar': [], 'Sanders': [], 'Warren': []}\n",
    "k = 30\n",
    "for i in range(k):\n",
    "    print('Fold ' + str(i) + ': ')\n",
    "    for candidate in candidates:\n",
    "        print(candidate + ': ')\n",
    "        X_train, Y_train, X_test, Y_test = get_data(candidate, debates, dictionary)\n",
    "        clf = select_classifier(c = 0.1)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "        accuracies[candidate].append(performance(Y_test, pred))\n",
    "        largest = pd.DataFrame(clf.coef_.T).nlargest(10, columns = 0)\n",
    "        smallest = pd.DataFrame(clf.coef_.T).nsmallest(10, columns = 0)\n",
    "        coefs[candidate].append(clf.coef_)\n",
    "        for index in range(largest.shape[0]):\n",
    "            words[candidate].append(list(dictionary)[largest.iloc[index].name])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparing Candidates\n",
    "### See which candidates are most distinct from every other candidate and which candidates are most and least similar to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Biden prediction accuracy: 0.7567676767676769\nButtigieg prediction accuracy: 0.7159090909090907\nKlobuchar prediction accuracy: 0.7011204481792718\nSanders prediction accuracy: 0.7496503496503497\nWarren prediction accuracy: 0.7293859649122806\n"
    }
   ],
   "source": [
    "for candidate in candidates:\n",
    "    print(candidate + ' prediction accuracy: ' + str(np.mean(accuracies[candidate])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Biden</th>\n      <th>Buttigieg</th>\n      <th>Klobuchar</th>\n      <th>Sanders</th>\n      <th>Warren</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Biden</th>\n      <td>6.676468</td>\n      <td>-0.673970</td>\n      <td>-0.918452</td>\n      <td>-0.277564</td>\n      <td>-0.695145</td>\n    </tr>\n    <tr>\n      <th>Buttigieg</th>\n      <td>-0.673970</td>\n      <td>5.851765</td>\n      <td>-0.439590</td>\n      <td>-0.861142</td>\n      <td>-0.870195</td>\n    </tr>\n    <tr>\n      <th>Klobuchar</th>\n      <td>-0.918452</td>\n      <td>-0.439590</td>\n      <td>4.755316</td>\n      <td>-0.328117</td>\n      <td>-0.314090</td>\n    </tr>\n    <tr>\n      <th>Sanders</th>\n      <td>-0.277564</td>\n      <td>-0.861142</td>\n      <td>-0.328117</td>\n      <td>5.427345</td>\n      <td>-0.695771</td>\n    </tr>\n    <tr>\n      <th>Warren</th>\n      <td>-0.695145</td>\n      <td>-0.870195</td>\n      <td>-0.314090</td>\n      <td>-0.695771</td>\n      <td>6.448461</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "              Biden  Buttigieg  Klobuchar   Sanders    Warren\nBiden      6.676468  -0.673970  -0.918452 -0.277564 -0.695145\nButtigieg -0.673970   5.851765  -0.439590 -0.861142 -0.870195\nKlobuchar -0.918452  -0.439590   4.755316 -0.328117 -0.314090\nSanders   -0.277564  -0.861142  -0.328117  5.427345 -0.695771\nWarren    -0.695145  -0.870195  -0.314090 -0.695771  6.448461"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignments = np.zeros((5, 5))\n",
    "avg_coefs = {}\n",
    "for candidate in candidates:\n",
    "    avg_coefs[candidate] = np.mean(np.array(coefs[candidate]), axis = 0)[0]\n",
    "for i, candidate1 in enumerate(candidates):\n",
    "    for j, candidate2 in enumerate(candidates):\n",
    "        alignments[i, j] = np.dot(avg_coefs[candidate1], avg_coefs[candidate2].T)\n",
    "\n",
    "alignments = pd.DataFrame(alignments)\n",
    "alignments.index = candidates\n",
    "alignments.columns = candidates\n",
    "alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Biden is most similar to Sanders\nBiden is least similar to Klobuchar\nButtigieg is most similar to Klobuchar\nButtigieg is least similar to Warren\nKlobuchar is most similar to Warren\nKlobuchar is least similar to Biden\nSanders is most similar to Biden\nSanders is least similar to Buttigieg\nWarren is most similar to Klobuchar\nWarren is least similar to Buttigieg\n"
    }
   ],
   "source": [
    "for candidate in candidates:\n",
    "    most = str(alignments[candidate][alignments[candidate] == max(alignments[alignments[candidate].index != candidate][candidate])].index[0])\n",
    "    least = str(alignments[candidate][alignments[candidate] == min(alignments[alignments[candidate].index != candidate][candidate])].index[0])\n",
    "    print(candidate + ' is most similar to ' + most)\n",
    "    print(candidate + ' is least similar to ' + least)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../candidate_word_weights.txt', 'w')\n",
    "for candidate in candidates:\n",
    "    f.write(candidate + ': \\n')\n",
    "    for i, word in enumerate(words[candidate]):\n",
    "        f.write(word + ': ' + str(avg_coefs[candidate][dictionary[words[candidate][i]]]) + '\\n')\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  }
 ]
}